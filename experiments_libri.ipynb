{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f6cda4c-f788-4416-b8b6-3cc1454bb589",
   "metadata": {},
   "source": [
    "# kNN-VC and LinearVC experiments using all data\n",
    "\n",
    "Herman Kamper, 2024\n",
    "\n",
    "The source frames only come from the input utterance, i.e. no other speech from\n",
    "the source speaker is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41bd31c2-06e9-43ea-b359-a7159626c8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from numpy import linalg\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import Lasso, LinearRegression, Ridge\n",
    "from tqdm.notebook import tqdm\n",
    "import IPython.display as display\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from utils import fast_cosine_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa02a4ca-ff1d-4234-ac1f-a51744d5bd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b79249-4cb5-4492-813f-34f938d252c8",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb5654b-d78e-4bdd-8b0f-a0c724863e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavlm = torch.hub.load(\"bshall/knn-vc\", \"wavlm_large\", trust_repo=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf4da88-f081-458b-b0ac-1b943d161012",
   "metadata": {},
   "outputs": [],
   "source": [
    "hifigan, _ = torch.hub.load(\"bshall/knn-vc\", \"hifigan_wavlm\", trust_repo=True, device=device, prematched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f1b3c0-f6d5-4f91-84f6-2516422418f8",
   "metadata": {},
   "source": [
    "## LinearVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450af097-56d6-470a-a2b7-cb9c626e58d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_tag = \"all_2024-09-17\"\n",
    "eval_csv = Path(\"data/speakersim_vctk_english.csv\")\n",
    "feats_dir = Path(\"/home/kamperh/scratch/vctk/wavlm\")\n",
    "wav_dir = Path(\"/home/kamperh/scratch/vctk/wav\")\n",
    "output_dir = Path(f\"/home/kamperh/scratch/linearvc/vctk/{exp_tag}\")\n",
    "\n",
    "n_frames = 8192  # 15000\n",
    "k_top = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e39098-c662-474c-802f-2e878a4d3778",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_dict = {}\n",
    "print(\"Reading from:\", feats_dir)\n",
    "for speaker_feats_fn in tqdm(sorted(feats_dir.glob(\"*.npy\"))):\n",
    "    speaker = speaker_feats_fn.stem\n",
    "    feats_dict[speaker] = (\n",
    "        torch.from_numpy(np.load(speaker_feats_fn))[:n_frames, :]\n",
    "        .float()\n",
    "        .to(device)\n",
    "    )\n",
    "print(\"No. speakers:\", len(feats_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f85bb72-c841-475b-8c62-b81625d40a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projection matrices\n",
    "projmats = {}\n",
    "for source in tqdm(feats_dict):\n",
    "    for target in tqdm(feats_dict, leave=False):\n",
    "        if source == target:\n",
    "            continue\n",
    "\n",
    "        source_feats = feats_dict[source]\n",
    "        target_feats = feats_dict[target]\n",
    "\n",
    "        dists = fast_cosine_dist(source_feats, target_feats, device=device)\n",
    "        best = dists.topk(k=k_top, largest=False, dim=-1)        \n",
    "        linear_target = target_feats[best.indices].mean(dim=1)\n",
    "\n",
    "        # W, _, _, _ = linalg.lstsq(source_feats.cpu(), linear_target.cpu())\n",
    "        \n",
    "        linear = Ridge(alpha=1e4, fit_intercept=False).fit(\n",
    "            source_feats.squeeze().cpu(), linear_target.cpu()\n",
    "        )\n",
    "        W = linear.coef_.T\n",
    "\n",
    "        W = torch.from_numpy(W).float().to(device)\n",
    "        projmats[f\"{source}-{target}\"] = W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f603dd-4b25-48a3-9a09-5f204c4b2abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(\"Writing to:\", output_dir)\n",
    "with open(eval_csv) as f:\n",
    "    for line in tqdm(f.readlines()):\n",
    "        line = line.strip()\n",
    "        if line[-1] == \"0\":\n",
    "            (source, target, source_key, _, _) = line.split(\",\")\n",
    "\n",
    "            source_wav_fn = (\n",
    "                wav_dir / source / Path(source_key).stem\n",
    "            ).with_suffix(\".wav\")\n",
    "            source_wav, _ = torchaudio.load(source_wav_fn)\n",
    "            source_wav = source_wav.to(device)\n",
    "            with torch.inference_mode():\n",
    "                source_feats, _ = wavlm.extract_features(\n",
    "                    source_wav, output_layer=6\n",
    "                )\n",
    "\n",
    "            W_source_to_target = projmats[f\"{source}-{target}\"]\n",
    "\n",
    "            source_to_target_feats = source_feats @ W_source_to_target\n",
    "\n",
    "            with torch.inference_mode():\n",
    "                wav_hat = hifigan(source_to_target_feats).squeeze(0)            \n",
    "\n",
    "            cur_output_dir = Path(output_dir) / source_key.split(\"/\")[0]\n",
    "            cur_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "            output_fn = (cur_output_dir / source_key.split(\"/\")[1]).with_suffix(\n",
    "                \".wav\"\n",
    "            )\n",
    "            torchaudio.save(output_fn, wav_hat.squeeze().cpu()[None], 16000)\n",
    "\n",
    "            print(output_fn)\n",
    "            assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763e8d9c-dc9d-41bf-9d01-db336725d210",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments: pass\n",
    "args = Arguments()\n",
    "args.format = \"vctk\"\n",
    "args.eval_csv = eval_csv\n",
    "args.converted_dir = output_dir\n",
    "args.groundtruth_dir = wav_dir\n",
    "\n",
    "print(\"Run:\")\n",
    "print(\n",
    "    f\"./speaker_similarity.py --format {args.format}\"\n",
    "    f\" {args.eval_csv} {args.converted_dir} {args.groundtruth_dir}\"\n",
    ")\n",
    "print(\n",
    "    f\"./intelligibility.py --format {args.format} {args.converted_dir}\"\n",
    "    f\" /home/kamperh/endgame/datasets/VCTK-Corpus/txt/\"\n",
    ")\n",
    "\n",
    "# speaker_similarity(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e109bf3d-dd80-48ec-80ff-d678c7b3aff3",
   "metadata": {},
   "source": [
    "## kNN-VC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67923bc-53a3-47fe-b59d-dac4d333e25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_tag = \"all_2024-09-17\"\n",
    "eval_csv = Path(\"data/speakersim_vctk_english.csv\")\n",
    "feats_dir = Path(\"/home/kamperh/scratch/vctk/wavlm\")\n",
    "wav_dir = Path(\"/home/kamperh/scratch/vctk/wav\")\n",
    "output_dir = Path(f\"/home/kamperh/scratch/knnvc/vctk/{exp_tag}\")\n",
    "\n",
    "n_frames = None  # 15000\n",
    "k_top = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a51fd7d-f3c9-40db-9339-1492829d2e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(\"Writing to:\", output_dir)\n",
    "with open(eval_csv) as f:\n",
    "    for line in tqdm(f.readlines()):\n",
    "        line = line.strip()\n",
    "        if line[-1] == \"0\":\n",
    "            (source, target, source_key, _, _) = line.split(\",\")\n",
    "\n",
    "            # Features\n",
    "            source_wav_fn = (\n",
    "                wav_dir / source / Path(source_key).stem\n",
    "            ).with_suffix(\".wav\")\n",
    "            source_wav, _ = torchaudio.load(source_wav_fn)\n",
    "            source_wav = source_wav.to(device)\n",
    "            with torch.inference_mode():\n",
    "                source_feats, _ = wavlm.extract_features(\n",
    "                    source_wav, output_layer=6\n",
    "                )\n",
    "            target_feats = feats_dict[target]\n",
    "\n",
    "            # Matching\n",
    "            dists = fast_cosine_dist(source_feats, target_feats, device=device)\n",
    "            best = dists.topk(k=k_top, largest=False, dim=-1)\n",
    "            source_to_target_feats = target_feats[best.indices].mean(dim=1)[None]\n",
    "\n",
    "            with torch.inference_mode():\n",
    "                wav_hat = hifigan(source_to_target_feats).squeeze(0)            \n",
    "\n",
    "            cur_output_dir = Path(output_dir) / source_key.split(\"/\")[0]\n",
    "            cur_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "            output_fn = (cur_output_dir / source_key.split(\"/\")[1]).with_suffix(\n",
    "                \".wav\"\n",
    "            )\n",
    "            torchaudio.save(output_fn, wav_hat.squeeze().cpu()[None], 16000)\n",
    "\n",
    "            print(output_fn)\n",
    "            assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682d693d-982d-4b83-9703-a0701af9acbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments: pass\n",
    "args = Arguments()\n",
    "args.format = \"vctk\"\n",
    "args.eval_csv = eval_csv\n",
    "args.converted_dir = output_dir\n",
    "args.groundtruth_dir = wav_dir\n",
    "\n",
    "print(\"Run:\")\n",
    "print(\n",
    "    f\"./speaker_similarity.py --format {args.format}\"\n",
    "    f\" {args.eval_csv} {args.converted_dir} {args.groundtruth_dir}\"\n",
    ")\n",
    "print(\n",
    "    f\"./intelligibility.py --format {args.format} {args.converted_dir}\"\n",
    "    f\" /home/kamperh/endgame/datasets/VCTK-Corpus/txt/\"\n",
    ")\n",
    "\n",
    "# speaker_similarity(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
